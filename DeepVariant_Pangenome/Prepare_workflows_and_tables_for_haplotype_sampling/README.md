## Preparing workflows for haplotype sampling and making GBZ files with different number of haplotypes
### Comment 1 : 01/29/2023

#### Modifying the haplotype sampling workflow
I created a fork of https://github.com/vgteam/vg_wdl in here https://github.com/mobinasri/vg_wdl to be able to make the changes I want in the workflows.
I made a customized version of Parsa's workflow for haplotype sampling. The original version is here: https://github.com/vgteam/vg_wdl/blob/master/workflows/haplotype_sampling.wdl and 
my version is here: https://github.com/mobinasri/vg_wdl/blob/master/workflows/haplotype_sampling_customized.wdl

The customized version can take an array of read files of any type. I imported `extract_reads.wdl` for extracting each read file, which can be either BAM,CRAM,FASTQ or FASTA.GZ
and receiving a fastq file. This haplotype sampling workflow will take a list of haplotype numbers and will create an array of gbz files; each one is a graph created with 
a different haplotype number. My main motivation for writing this WDL was that we are going to train multiple models with different number of haplotypes and then investigate which one acheives
a higher accuracy. For this aim we need to create multiple gbz files for different haplotype numbers. With this WDL we can run the workflow only once and create all the graphs 
that we need. 

#### Preparing csv files for tesing the workflow

I'm going to use one of the bam files Parsa generated by mapping short reads to GRCh38 with Giraffe. I will use this one:
```
gs://pepper-deepvariant/seeskand/dv_training/HG003_35x_merged.positionsorted.bam
gs://pepper-deepvariant/seeskand/dv_training/HG003_35x_merged.positionsorted.bam.bai
```
